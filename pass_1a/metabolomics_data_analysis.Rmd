---
title: "BIC metabolomics data analysis"
output:
  pdf_document: 
    number_sections: true
  html_notebook: default
---

In this document we present the joint analysis of the PASS1A metabolomics datasets.

# Load all datasets

Load the data from the cloud, including: phenotypic data, metabolomic datasets, and metabolomics dictionary.

```{r,results='hide',message=FALSE,warning=FALSE}
source("~/Desktop/repos/motrpac-bic-norm-qc/tools/supervised_normalization_functions.R")
source("~/Desktop/repos/motrpac-bic-norm-qc/tools/unsupervised_normalization_functions.R")
source("~/Desktop/repos/motrpac-bic-norm-qc/tools/gcp_functions.R")
source("~/Desktop/repos/motrpac-bic-norm-qc/tools/association_analysis_methods.R")
source("~/Desktop/repos/motrpac-bic-norm-qc/tools/data_aux_functions.R")
source("~/Desktop/repos/motrpac/tools/prediction_ml_tools.R")
library(randomForest) # for classification tests

# Load the dmaqc data
merged_dmaqc_data =  load_from_bucket("merged_dmaqc_data2019-10-15.RData",
    "gs://bic_data_analysis/pass1a/pheno_dmaqc/",F)
merged_dmaqc_data = merged_dmaqc_data[[1]]
rownames(merged_dmaqc_data) = as.character(merged_dmaqc_data$vial_label)
# define the tissue variable
merged_dmaqc_data$tissue = merged_dmaqc_data$sampletypedescription
# define the time to freeze variable
merged_dmaqc_data$time_to_freeze = merged_dmaqc_data$calculated.variables.time_death_to_collect_min + 
  merged_dmaqc_data$calculated.variables.time_collect_to_freeze_min

# Load our parsed metabolomics datasets
metabolomics_parsed_datasets = load_from_bucket(
  file = "metabolomics_parsed_datasets_ER_PHASE1A-06.RData",
  bucket = "gs://bic_data_analysis/pass1a/metabolomics/")[[1]]

# Read the dictionary
dict_bucket = 
  "gs://motrpac-external-release1-results/metabolomics_targeted/motrpac_metabolomics_data_dictionary-v1.1.5.txt"
dict_download = get_single_file_from_bucket_to_local_dir(dict_bucket)
metabolomics_dict = fread(dict_download[[1]],data.table = F)

# Plot cv vs means
d = metabolomics_parsed_datasets[["white_adipose_powder,metab_u_hilicpos,unnamed"]]
dx = d$sample_data
CoV<-function(x){return(sd(x,na.rm = T)/mean(x,na.rm=T))}
dmeans = apply(dx,1,mean,na.rm=T)
CoVs = apply(dx,1,CoV)
inds = !is.na(CoVs)
df = data.frame(Mean_intensity = dmeans[inds],CoV = CoVs[inds])
plot(CoV~Mean_intensity,df,cex=0.5,pch=20)
lines(lowess(CoV~Mean_intensity,df),lty=2,lwd=2,col="blue")

dx = log(1+d$sample_data,base=2)
dmeans = apply(dx,1,mean,na.rm=T)
CoVs = apply(dx,1,CoV)
inds = !is.na(CoVs)
df = data.frame(Mean_intensity = dmeans[inds],CoV = CoVs[inds])
plot(CoV~Mean_intensity,df,cex=0.5,pch=20)
lines(lowess(CoV~Mean_intensity,df),lty=2,lwd=2,col="blue")

# Plot number of NAs vs intensity mean
dx = log(1+d$sample_data,base=2)
dmeans = apply(dx,1,mean,na.rm=T)
num_nas = rowSums(is.na(dx))
df = data.frame(Num_NAs = num_nas[inds],Mean_intensity = dmeans[inds])
plot(Num_NAs~Mean_intensity,df,cex=0.5,pch=20)
lines(lowess(Num_NAs~Mean_intensity,df),lty=2,lwd=2,col="blue")
cor(df$Num_NAs,df$Mean_intensity,method="spearman")

```

Define the variables to be adjusted for:
```{r}
biospec_cols = c(
  "acute.test.distance",
  "calculated.variables.time_to_freeze",
  "calculated.variables.edta_coll_time",
  "bid" # required for matching datasets
  )
differential_analysis_cols = c(
  "animal.registration.sex",
  "animal.key.timepoint",
  "animal.key.is_control"
)
pipeline_qc_cols = c("sample_order")
```

# Data filtering and normalization

We go over each dataset. We merged the named and unnamed subparts of the untargeted datasets, then: (1) log the data (values are raw intensities), (2) remove rows with $>20\%$ missing values, and (3) impute missing values.

Important: datasets that do not have unique metabolite names or sample ids probably had errors while parsing and are therefore ignored. Also, untargeted with failed mergning of the unnamed and named subsets (e.g., due to different sample ids) are ignored as well.

Finally we add an additional version for each dataset by directly regressing out the sample order component. See https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4757603/ for more details (trend correction is also called background correction, and this is done for each batch separately).

```{r,out.height='50%',out.width='50%',message=T,warning=FALSE}
metabolomics_processed_datasets = c()
# set a binary vector indicating with entries to skip
metabolomics_raw_datasets_skip = rep(F,length(metabolomics_parsed_datasets))
names(metabolomics_raw_datasets_skip) = names(metabolomics_parsed_datasets)
untargeted_merge_errors = list()
for(currname in names(metabolomics_parsed_datasets)){
  
  if(metabolomics_raw_datasets_skip[currname]){next}
  
  arr = strsplit(currname,split=",")[[1]]
  arr = arr[-length(arr)]
  name1 = paste(paste(arr,collapse=","),"named",sep=",")
  name2 = paste(paste(arr,collapse=","),"unnamed",sep=",")
  
  # If dataset is untargeted, merge named and unnamed, update the dataset
  # currname. Skip the dataset if the merge fails, but store and print the errror.
  if(name2 %in% names(metabolomics_parsed_datasets)){
    d1 = metabolomics_parsed_datasets[[name1]]
    d2 = metabolomics_parsed_datasets[[name2]]
    newd = NULL
    tryCatch({
      newd = merge_named_and_unnamed_metabolomics_datasets(d1,d2,strict = F)
      }, error = function(e) {}) # can add error handling here
    currname = paste(paste(arr,collapse=","),"untargeted",sep=",")
    metabolomics_raw_datasets_skip[name1] = T
    metabolomics_raw_datasets_skip[name2] = T
    if(is.null(newd)){
      print(paste("# Skipping dataset",
                  currname,
                  "because merging the named and unnamed subsets failed"))
      next
    }
  }
  else{
    metabolomics_raw_datasets_skip[currname] = T
    newd = metabolomics_parsed_datasets[[currname]]
  }
  
  print(paste("#### Analyzing data from:",currname))
  curr_data  = newd$sample_data
  curr_data2 = recast_numeric_data_frame(curr_data)
  curr_data_mat = as.matrix(curr_data2)
  print(paste("no errors in parsing numeric values:",all(curr_data==curr_data_mat,na.rm=T)))

  # floor the data at 0
  curr_data_mat[curr_data_mat<0] = 0
  # log the data (in required)
  is_logged = F
  if(max(curr_data_mat,na.rm = T)>200){
    curr_data = log(curr_data_mat+1,base=2)
    is_logged = T
  }
  
  # organize the metadata
  curr_meta = merged_dmaqc_data[colnames(curr_data),
        union(biospec_cols,differential_analysis_cols)]
  # remove metadata variables with too many NAs
  na_counts = apply(is.na(curr_meta),2,sum)
  curr_meta = curr_meta[,na_counts/nrow(curr_meta) < 0.1]
  
  # Look at the sample order
  curr_order = newd$sample_meta[rownames(curr_meta),"sample_order"]

  # organize the dataset
  curr_data = curr_data[,rownames(curr_meta)]
  # remove zero variance rows or rows with many NAs
  rows_to_rem = !(apply(curr_data,1,sd,na.rm=T)>0)
  percent_na = rowSums(is.na(curr_data)) / ncol(curr_data)
  print(paste("number of NA cells:",sum(is.na(curr_data))))
  rows_to_rem = rows_to_rem | percent_na > 0.2
  # remove rows with no annotation
  rows_to_rem = rows_to_rem | newd$data_raw_rownames == ""
  rows_to_rem = rows_to_rem | newd$data_raw_rownames == "-"
  rows_to_rem = rows_to_rem | newd$data_raw_rownames == "_"
  rows_to_rem = rows_to_rem | is.na(newd$data_raw_rownames)
  # remove rows with duplicated representation
  row_duplications = names(which(table(newd$data_raw_rownames)>1))
  if(any(newd$data_raw_rownames[!rows_to_rem] %in% row_duplications)){
    rows_to_rem = rows_to_rem | newd$data_raw_rownames %in% row_duplications
    print("# WARNING: dataset has duplicated row names whose data are now ignored")
    print(paste(row_duplications,collapse=","))
  }
  curr_data = curr_data[!rows_to_rem,]
  # impute - use capture.output to avoid prints
  capture.output(
    {curr_data_imp = impute::impute.knn(as.matrix(curr_data))$data}
    ,file=NULL)
  curr_data_rnames = newd$data_raw_rownames[!rows_to_rem]
  rownames(curr_data_imp) = curr_data_rnames
  
  # Regress out the sample order
  # lm_regress_matrix works on columns
  curr_data_imp2 = t(lm_regress_out_matrix(t(curr_data_imp),curr_order))
  
  # update the data object
  metabolomics_processed_datasets[[currname]] = newd
  metabolomics_processed_datasets[[currname]]$sample_data = curr_data_imp
  metabolomics_processed_datasets[[currname]]$data_raw_rownames = curr_data_rnames
  metabolomics_processed_datasets[[currname]]$sample_meta_parsed = curr_meta
  metabolomics_processed_datasets[[currname]]$sample_data_order_adj = curr_data_imp2
  metabolomics_processed_datasets[[currname]]$is_logged = is_logged
}

save_to_bucket(metabolomics_processed_datasets,
               file="metabolomics_processed_datasets10202019.RData",
               bucket = "gs://bic_data_analysis/pass1a/metabolomics/")

```


Alternatively load the result from the bucket to save time:
```{r}
metabolomics_processed_datasets = load_from_bucket(
  file="metabolomics_processed_datasets10202019.RData",
  bucket = "gs://bic_data_analysis/pass1a/metabolomics/"
)[[1]]
```

# Examine the unlogged data

Untargeted data are typically logged and analyzed using linear models. On the other hand, concentration data are analyzed with the same type of models but using the original data. This raises a problem if we wish to compare exact statistics from these data. In this section we perform residual analysis for single metabolites. Our goal is to identify if concentration data behaves "normally" when not logged. The analysis below examines the residuals of the data and uses qq-plots to determine if a log transformation is indeed required.

```{r,out.height='50%',out.width='50%',message=T,warning=FALSE}
is_normal_test<-function(v,samp=10000){
  return(ks.test(v,"pnorm",mean(v,na.rm=T),sd(v,na.rm = T))$p.value)
}
# go over the named datasets, get a logged and an unlogged version of
# the data, use these as inputs for the regression
residual_analysis_results = list()
for(nn1 in names(metabolomics_processed_datasets)){
  if(grepl("untargeted",nn1)){next}
  x = metabolomics_processed_datasets[[nn1]]$sample_data_order_adj
  if(metabolomics_processed_datasets[[nn1]]$is_logged){
    x_log = x
    x_unlog = 2^x
  }
  else{
    x_log = log2(1+x)
    x_unlog = x
  }
  
  # take the covariates, ignore distances
  x_meta = unique(metabolomics_processed_datasets[[nn1]]$sample_meta_parsed)
  curr_covs = x_meta[,intersect(colnames(x_meta),biospec_cols[-1])]
  curr_covs = data.frame(curr_covs,
           sex=x_meta$animal.registration.sex)
  
  # get the lm objects
  curr_models = list()
  for(tp in unique(x_meta$animal.key.timepoint)){
      res_log = apply(
        x_log,1,
        pass1a_simple_differential_abundance,
        tps = y_meta$animal.key.timepoint,tp=tp,
        is_control = y_meta$animal.key.is_control,
        covs = curr_covs,return_model=T
      )
      res_unlog = apply(
        x_unlog,1,
        pass1a_simple_differential_abundance,
        tps = y_meta$animal.key.timepoint,tp=tp,
        is_control = y_meta$animal.key.is_control,
        covs = curr_covs,return_model=T
      )
      is_norm = cbind(
        sapply(res_log,function(x)is_normal_test(residuals(x))),
        sapply(res_unlog,function(x)is_normal_test(residuals(x)))
      )
      colnames(is_norm) = c("log","not log")
      curr_models[[as.character(tp)]] = is_norm
  }
  residual_analysis_results[[nn1]] = curr_models
}

log_vs_unlog_summ_mat = sapply(residual_analysis_results,
    function(x)sapply(x,
        function(y)
          wilcox.test(y[,1],y[,2],paired = T,alternative = "g")$p.value))

library(ggcorrplot)
print(ggcorrplot(t(log_vs_unlog_summ_mat),lab=T,lab_size=2.5,hc.order = F,
                  ) +
        ggtitle("Logged data more normal?") +
        theme(plot.title = element_text(hjust = 0.5,size=20)))
library(corrplot)
corrplot(t(-log10(log_vs_unlog_summ_mat)),is.corr = F)


```


# Analysis of specific metabolites

Compare overlaps, effect sizes, and correlations within tissues. Compare targeted-untargeted pairs only.

```{r,out.height='50%',out.width='50%',message=T,warning=FALSE}

# helper function to transform a metabolomics matrix
# to that of its motrpac compound ids
extract_metab_data_from_row_annot<-function(x,row_annot_x){
  # get the coloumn that has the row names
  int_sizes = apply(row_annot_x,2,function(x,y)length(intersect(x,y)),y=rownames(x))
  ind = which(int_sizes==max(int_sizes,na.rm = T))
  row_annot_x = row_annot_x[is.element(row_annot_x[,ind],set=rownames(x)),]
  rownames(row_annot_x) = row_annot_x[,ind]
  shared = intersect(rownames(row_annot_x),rownames(x))
  x = x[shared,]
  row_annot_x = row_annot_x[shared,]
  rownames(x) = row_annot_x$motrpac_comp_name
  return(x)
}

single_metabolite_corrs = list()
single_metabolite_de = c()
for(nn1 in names(metabolomics_processed_datasets)){
  nn1_tissue = strsplit(nn1,split=",")[[1]][1]
  nn1_tissue = gsub("_powder","",nn1_tissue)
  nn1_dataset = strsplit(nn1,split=",")[[1]][2]
  if(grepl("untargeted",nn1)){next}
  single_metabolite_corrs[[nn1]] = list()
  for(nn2 in names(metabolomics_processed_datasets)){
    if(nn2 == nn1){next}
    if(grepl(",named",nn2)){next}
    nn2_tissue = strsplit(nn2,split=",")[[1]][1]
    nn2_tissue = gsub("_powder","",nn2_tissue)
    nn2_dataset = strsplit(nn2,split=",")[[1]][2]
    if(nn1_tissue!=nn2_tissue){next}
    # get the numeric dataset
    x = metabolomics_processed_datasets[[nn1]]$sample_data_order_adj
    # x = log2(x+1)
    y = metabolomics_processed_datasets[[nn2]]$sample_data_order_adj
    print(paste("dataset1:",nn1))
    print(range(x))
    print(paste("dataset2:",nn2))
    print(range(y))
    row_annot_x = metabolomics_processed_datasets[[nn1]]$row_annot
    row_annot_y = metabolomics_processed_datasets[[nn2]]$row_annot
    # transform metabolite names to the motrpac comp name
    x = extract_metab_data_from_row_annot(x,row_annot_x)
    y = extract_metab_data_from_row_annot(y,row_annot_y)
    # align the sample sets
    bid_y = merged_dmaqc_data[colnames(y),"bid"]
    bid_x = merged_dmaqc_data[colnames(x),"bid"]    
    # step 1: merge samples from the same BID
    if(length(unique(bid_x))!=length(bid_x)){
      x = aggregate_repeated_samples(x,bid_x)
    }
    else{
      colnames(x) = bid_x
    }
    if(length(unique(bid_y))!=length(bid_y)){
      y = aggregate_repeated_samples(y,bid_y)
    }else{
      colnames(y) = bid_y
    }
    # step 2: use the shared bio ids
    shared_bids = as.character(intersect(colnames(y),colnames(x)))
    x = as.matrix(x[,shared_bids])
    y = as.matrix(y[,shared_bids])
    # At this point x and y are over the same BIDs, now we add the metadata
    y_meta = unique(metabolomics_processed_datasets[[nn1]]$sample_meta_parsed)
    rownames(y_meta) = y_meta$bid
    y_meta = y_meta[shared_bids,]
    
    # get the shared matebolites
    shared_metabolites = intersect(rownames(x),rownames(y))
    shared_metabolites = na.omit(shared_metabolites)
    if(length(shared_metabolites)==0){next}
    
    # Get statistics
    corrs = c();de_res = c()
    for(metabolite in shared_metabolites){
      # a simple correlation over all samples
      corrs[metabolite] = 
        cor(x[metabolite,],y[metabolite,],method = "spearman")
    }
    
    # take the covariates, ignore distances
    curr_covs = y_meta[,intersect(colnames(y_meta),biospec_cols[-1])]
    curr_covs = data.frame(curr_covs,
                           sex=y_meta$animal.registration.sex)
    
      # differential analysis
    for(tp in unique(y_meta$animal.key.timepoint)){
      resx = t(apply(
        matrix(x[shared_metabolites,],nrow=length(shared_metabolites)),1,
        pass1a_simple_differential_abundance,
        tps = y_meta$animal.key.timepoint,tp=tp,
        is_control = y_meta$animal.key.is_control,
        covs = curr_covs
      ))
      resy = t(apply(
        matrix(y[shared_metabolites,],nrow=length(shared_metabolites)),1,
        pass1a_simple_differential_abundance,
        tps = y_meta$animal.key.timepoint,tp=tp,
        is_control = y_meta$animal.key.is_control,
        covs = curr_covs
      ))
      # Add dataset information, time point, tissue
      added_columns = matrix(cbind(
        rep(nn1_dataset,length(shared_metabolites)),
        rep(nn2_dataset,length(shared_metabolites)),
        shared_metabolites,
        rep(tp,length(shared_metabolites)),
        rep(nn1_tissue,length(shared_metabolites))
      ),nrow=length(shared_metabolites))
      resx = cbind(resx,rep(T,nrow(resx)))
      colnames(resx)[ncol(resx)] = "is_targeted"
      resy = cbind(resy,rep(F,nrow(resy)))
      colnames(resy)[ncol(resy)] = "is_targeted"
      if(nrow(resx)>1){
        resx = cbind(added_columns[,-2],resx)
        resy = cbind(added_columns[,-1],resy)
      }
      else{
        resx = c(added_columns[,-2],resx)
        resy = c(added_columns[,-1],resy)
      }
      single_metabolite_de = rbind(single_metabolite_de,resx)
      single_metabolite_de = rbind(single_metabolite_de,resy)
    }
    
    single_metabolite_corrs[[nn1]][[nn2]] = corrs
  }
}
single_metabolite_de = unique(single_metabolite_de)
single_metabolite_de = data.frame(single_metabolite_de)
names(single_metabolite_de) = c(
  "dataset","metabolite","tp","tissue",
  "Est","Std","Tstat","Pvalue","is_targeted")
for(col in names(single_metabolite_de)[-c(1:4)]){
  single_metabolite_de[[col]] = as.numeric(
    as.character(single_metabolite_de[[col]]))
}
for(col in names(single_metabolite_de)[1:4]){
  single_metabolite_de[[col]] = 
    as.character(single_metabolite_de[[col]])
}

```

We now show some plots to summarize the comparison. We plot the overall average correlation between the platforms (within tissues). However, going into a single metabolite comparison in detail (again, within tissues), for each metabolite, in each time point we perform a meta-analysis of the effects and examine the significance and heterogeneity.

```{r,out.height='50%',out.width='50%',message=T,warning=FALSE}

meta_analysis_stats = list()
for(tissue in unique(single_metabolite_de$tissue)){
  for(tp in unique(single_metabolite_de$tp)){
    curr_subset = single_metabolite_de[
      curr_subset$tissue==tissue & curr_subset$tp==tp,]
    for(metabolite in unique(curr_subset$metabolite)){
      curr_met_data = curr_subset[
        curr_subset$metabolite==metabolite,]
    }
  }
}

```

# Dataset pairwise comparison as a prediction task

Use 10-fold cross validation for analysis within tissues.

```{r,fig.align="center",out.height='60%',out.width='60%',eval=FALSE}
nfolds = 10
prediction_analysis_results = list()
for(nn1 in names(metabolomics_processed_datasets)){
  nn1_tissue = strsplit(nn1,split=",")[[1]][1]
  nn1_tissue = gsub("_powder","",nn1_tissue)
  for(nn2 in names(metabolomics_processed_datasets)){
    nn2_tissue = strsplit(nn2,split=",")[[1]][1]
    nn2_tissue = gsub("_powder","",nn2_tissue)
    if(nn1_tissue!=nn2_tissue){next}
    print(paste("training set:",nn2))
    print(paste("test set:",nn1))
    
    # get the data, merge samples by bid if necessary
    y = metabolomics_processed_datasets[[nn1]]$sample_data
    x = metabolomics_processed_datasets[[nn2]]$sample_data
    y_meta = unique(metabolomics_processed_datasets[[nn1]]$sample_meta_parsed)
    # # remove metadata variables with too many NAs
    # na_counts = apply(is.na(y_meta),2,sum)
    # y_meta = y_meta[,na_counts/nrow(y_meta) == 0]
    rownames(y_meta) = y_meta$bid
    bid_y = merged_dmaqc_data[colnames(y),"bid"]
    bid_x = merged_dmaqc_data[colnames(x),"bid"]    
    # merge samples from the same BID
    if(length(unique(bid_x))!=length(bid_x)){
      x = aggregate_repeated_samples(x,bid_x)
    }
    else{
      colnames(x) = bid_x
    }
    if(length(unique(bid_y))!=length(bid_y)){
      y = aggregate_repeated_samples(y,bid_y)
    }else{
      colnames(y) = bid_y
    }
    
    if(ncol(y)>1000){next}
    
    cov_cols = intersect(colnames(y_meta),
                          setdiff(biospec_cols,"bid"))
    covs = as.matrix(y_meta[colnames(y),cov_cols])
    
    # regress the covariates out - simple linear analysis
    y = lm_regress_out_matrix(t(y),covs)
    
    # Prepare the input for the ML part
    shared_bids = as.character(intersect(rownames(y),colnames(x)))
    x = t(as.matrix(x[,shared_bids]))
    y = as.matrix(y[shared_bids,])
    
    # Run the regressions
    folds = sample(rep(1:nfolds,(1+nrow(x)/nfolds)))[1:nrow(x)]
    numFeatures = min(ncol(x),2000)
    preds = c();real=c()
    for(i in 1:ncol(y)){
      y_i = y[,1]
      i_preds = c();i_real=c()
      for(j in 1:nfolds){
        print(j)
        tr_x = x[folds!=j,]
        tr_yi = y_i[folds!=j]
        te_x = x[folds==j,]
        te_y = y_i[folds==j]
        # random forest
        # model = randomForest(tr_yi,x=tr_x,ntree = 20)
        # te_preds = predict(model,newdata = te_x)
        model = feature_selection_wrapper(tr_x,tr_yi,
                   coeff_of_var,randomForest,
                   topK = numFeatures,ntree=50)
        te_preds = predict(model,newdata = te_x)
        i_preds = c(i_preds,te_preds)
        i_real = c(i_real,te_y)
      }
      preds = cbind(preds,i_preds)
      real = cbind(real,i_real)
    }
    currname = paste(nn1,nn2,sep=";")
    prediction_analysis_results[[currname]] = list(
      preds = preds,real=real
    )
  }
}
names(prediction_analysis_results)

cov_prediction_analysis_results = list()
for(nn1 in names(metabolomics_processed_datasets)){
  print(nn1)
  y = metabolomics_processed_datasets[[nn1]]$sample_data
  y_vials = colnames(y)
  bid_y = merged_dmaqc_data[colnames(y),"bid"]
  colnames(y) = bid_y
  y = t(as.matrix(y))
  if(ncol(y)>1000){next}
  cov_cols = c("animal.registration.sex",
             "acute.test.weight",
             "acute.test.distance",
             "animal.key.timepoint")
  covs = merged_dmaqc_data[y_vials,cov_cols]
  x = covs
  
  # Run the regressions
  folds = sample(rep(1:nfolds,(1+nrow(x)/nfolds)))[1:nrow(x)]
  numFeatures = min(ncol(x),2000)
  preds = c();real=c()
  for(i in 1:ncol(y)){
    y_i = y[,1]
    i_preds = c();i_real=c()
    for(j in 1:nfolds){
      print(j)
      tr_x = x[folds!=j,]
      tr_yi = y_i[folds!=j]
      te_x = x[folds==j,]
      te_y = y_i[folds==j]
      # random forest
      model = randomForest(tr_yi,x=tr_x,ntree = 20)
      te_preds = predict(model,newdata = te_x)
      i_preds = c(i_preds,te_preds)
      i_real = c(i_real,te_y)
    }
    preds = cbind(preds,i_preds)
    real = cbind(real,i_real)
  }
  cov_prediction_analysis_results[[nn1]] = list(
      preds = preds,real=real
    )
}

results_metrics = c()
for(nn in names(prediction_analysis_results)){
  preds = prediction_analysis_results[[nn]]$preds
  real = prediction_analysis_results[[nn]]$real
  rhos1 = diag(cor(preds,real))
  rhos2 = diag(cor(preds,real,method="spearman"))
  SEs = (preds-real)^2
  mse = mean(SEs)
  normSEs = SEs / apply(real,2,sd)
  curr_scores = c(mean(rhos1),mean(rhos2),min(rhos1),min(rhos2),
                  mse,mean(normSEs))
  names(curr_scores) = c("mean_rho","mean_spearman_rho","min_rho","min_spearman_rho",
                         "MSE","mean MSE/SD")
  results_metrics = rbind(results_metrics,
                          curr_scores)
  rownames(results_metrics)[nrow(results_metrics)] = nn
}

cov_results_metrics = c()
for(nn in names(cov_prediction_analysis_results)){
  preds = cov_prediction_analysis_results[[nn]]$preds
  real = cov_prediction_analysis_results[[nn]]$real
  rhos1 = diag(cor(preds,real))
  rhos2 = diag(cor(preds,real,method="spearman"))
  SEs = (preds-real)^2
  mse = mean(SEs)
  normSEs = SEs / apply(real,2,sd)
  curr_scores = c(mean(rhos1),mean(rhos2),min(rhos1),min(rhos2),
                  mse,mean(normSEs))
  names(curr_scores) = c("mean_rho","mean_spearman_rho","min_rho","min_spearman_rho",
                         "MSE","mean MSE/SD")
  cov_results_metrics = rbind(cov_results_metrics,
                          curr_scores)
  rownames(cov_results_metrics)[nrow(cov_results_metrics)] = nn
}

# Some boxplots
pred_targets = sapply(names(prediction_analysis_results),function(x)
  strsplit(x,split = ";")[[1]][1])
target = "liver_powder,metab_t_tca,named" 
curr_res = unique(results_metrics[pred_targets == target,])
rownames(curr_res) = gsub(target,"",rownames(curr_res))
rownames(curr_res) = gsub(";","",rownames(curr_res))
rownames(curr_res)[rownames(curr_res)==""] = target
cov_baseline = cov_results_metrics[target,]

par(mar = c(8,4,2,2))
cols = rep("blue",nrow(curr_res))
cols[rownames(curr_res)==target] = "black"
plt = barplot(curr_res[,4],beside = T,xaxt="n",legend=F,
              ylab="Min rho (Spearman)",
              ylim = c(0.5,1),xpd=F,col=cols,
              main = target)
text(plt, par("usr")[3], labels = rownames(curr_res), 
     srt = 45, adj = c(1.1,1.1), xpd = T, cex=0.6)
abline(h=cov_baseline[4],lty=2,lwd=2,col="red")

par(mar = c(8,4,2,2))
plt = barplot(curr_res[,6],beside = T,xaxt="n",legend=F,
              ylab="Mean standardized SE",xpd=F,
              main = target,col=cols)
text(plt, par("usr")[3], labels = rownames(curr_res), 
     srt = 45, adj = c(1.1,1.1), xpd = T, cex=0.6)
abline(h=cov_baseline[6],lty=2,lwd=2,col="red")

# preds = c();real=c()
# for(j in 1:nfolds){
#   tr_x = x[folds!=j,]
#   tr_y = y[folds!=j,]
#   te_x = x[folds==j,]
#   te_y = y[folds==j,]
#   model = MTL_wrapper(tr_x,tr_y,type="Regression", Regularization="L21")
#   te_preds = predict(model,te_x)
#   real = rbind(real,te_y)
#   preds = rbind(preds,te_preds)
# }
# diag(cor(preds,real))

# Using PLS regression
# library(pls)
# pls_model = plsr(y~x,ncomp = 5,validation="LOO")
# eval = MSEP(pls_model)
# 
# y_pca = prcomp(y)
# plot(y_pca)
# explained_var = y_pca$sdev^2/sum(y_pca$sdev^2)
# y_pca_matrix = y_pca$x[,1:10]
# 
# # regress out sex, weight
# 
# get_explained_variance_using_PCA(x,y)
# x = apply(x,2,regress_out,covs=covs)
# y = apply(y,2,regress_out,covs=covs)
# get_explained_variance_using_PCA(x,y)


```

## Comparison of covariance matrices

```{r}

CV <-function(x){
  return(sd(x)/mean(x))
}

# Get all correlation and covariance matrices
y = metabolomics_parsed_datasets[[1]]$sample_data # anchor all datasets by these ids
y_vials = colnames(y)
bid_y = as.character(merged_dmaqc_data[colnames(y),"bid"])
cov_cols = c("animal.registration.sex",
             "acute.test.weight",
             "acute.test.distance")
covs = merged_dmaqc_data[y_vials,cov_cols]

cov_matrices = list()
cor_matrices = list()
for(nn in names(metabolomics_parsed_datasets)){
  x = metabolomics_parsed_datasets[[nn]]$sample_data
  bid_x = as.character(merged_dmaqc_data[colnames(x),"bid"])
  print(sum(!is.element(bid_y,set=bid_x))) # should be zero
  colnames(x) = bid_x
  x = x[,bid_y]
  # x = apply(x,1,regress_out,covs=covs)
  # x = t(x)
  # cvs = apply(x,1,CV)
  # print(table(cvs>0.5))
  # x = x[cvs>0.5,]
  # pcax = t(prcomp(t(x),scale. = F)$x[,1:10])
  cov_matrices[[nn]] = cov(x)
  cor_matrices[[nn]] = cor(x)
}
sapply(cor_matrices,dim)
library('evolqg');library(corrplot)
mantel_tests= MantelCor(cor_matrices)
mcors= MatrixCor(cor_matrices)
mcors = as.matrix(forceSymmetric(mcors,uplo="L"))
mantel_tests = as.matrix(
  forceSymmetric(mantel_tests$probabilities,uplo = "L"))
# diag(mantel_tests)=0
ord = corrplot(t(mcors),order="hclust")
ord = rownames(ord)
corrplot(mcors[ord,ord],p.mat=mantel_tests[ord,ord],
         insig = "label_sig",method="shade",
         sig.level = c(.0001, .001, .01),
         pch.cex = .9, pch.col = "black")
# rs_res = RandomSkewers(cor_matrices)
# corrplot(rs_res$correlations,
#          p.mat=mantel_tests$probabilities,type="lower",
#          insig = "label_sig",method="shade",
#          sig.level = c(.0001, .001, .01),
#          pch.cex = .9, pch.col = "black",tl.cex=0.6)

library(psych)

r1 = cor_matrices[[1]]
r2 = cor_matrices[[8]]
cor(r1[lower.tri(r1)],r2[lower.tri(r2)])
mantel_tests[1,8]
mantel_tests[8,1]

threshold_comp = apply_function_on_pairs(cor_matrices,
          function(x,y)sum(x>0.7&y>0.7))
corrplot(threshold_comp,is.corr = F,order="hclust")

threshold_comp = apply_function_on_pairs(cor_matrices,
         function(x,y)mean(diag(cor(x,y))))
corrplot(threshold_comp,is.corr = F,order="hclust")

```

# Integrarion with RNAseq

```{r}
rnaseq_data_for_difftests = load_from_bucket(
  "rnaseq_data_for_difftests.RData",
  "gs://bic_data_analysis/pass1a/rnaseq/"
)[[1]]
met_vs_rnaseq_cors = c()
for(nn in names(rnaseq_data_for_difftests)){
  d = rnaseq_data_for_difftests[[nn]]$fpkms
  covs = rnaseq_data_for_difftests[[nn]]$dmaqc_meta[,cov_cols]
  
  cvs = apply(d,1,CV)
  print(table(cvs>0.25))
  x = d[cvs>0.25,]
  # x = apply(x,1,regress_out,covs=covs)
  # x = t(x)
  
  bid_x = sapply(colnames(x),substr,1,5)
  print(sum(!is.element(bid_y,set=bid_x))) # should be zero
  colnames(x) = bid_x
  x = x[,bid_y]
  
  curr_cors = cor(x)
  v = c()
  for(nn2 in names(cor_matrices)){
    v[nn2] = MatrixCor(curr_cors,cor_matrices[[nn2]])
  }
  met_vs_rnaseq_cors = rbind(met_vs_rnaseq_cors,v)
  rownames(met_vs_rnaseq_cors)[nrow(met_vs_rnaseq_cors)] = nn
}
library(gplots)
heatmap.2(t(met_vs_rnaseq_cors),
          trace="none",scale=NULL,mar=c(15,15),
          key.xlab = "Correlation",
          col=redblue(200), breaks=seq(-1,1,0.01))

```

# Looking at metabolite overlap

```{r,fig.align="center",out.height='50%',out.width='80%',message=FALSE,warning=FALSE}
metabolite_sets = list()
for(nn in names(metabolomics_parsed_datasets)){
  an = metabolomics_parsed_datasets[[nn]]$row_annot
  name_cols = colnames(an)[grepl("_name",colnames(an),ignore.case = T)]
  metabolite_sets[[nn]] = unique(tolower(an[,name_cols[1]]))
}
overlap_matrix = apply_function_on_pairs(metabolite_sets,
                                         function(x,y)length(intersect(x,y)))
corrplot(log(overlap_matrix+1,10),is.corr = F)


site_cor_comparison = apply_function_on_pairs(
  metabolomics_parsed_datasets,
  compare_two_met_sites,print_progress = T,
  merged_dmaqc_data = merged_dmaqc_data,samplesize=500
)

site_cor_comparison[is.na(site_cor_comparison)]=0
corrplot(site_cor_comparison,order="hclust")

compare_two_met_sites<-function(x,y,merged_dmaqc_data,samplesize=100,...){
  an_x = x$row_annot
  name_colsx = colnames(an_x)[grepl("_name",colnames(an_x),ignore.case = T)]
  an_y = y$row_annot
  name_colsy = colnames(an_y)[grepl("_name",colnames(an_y),ignore.case = T)]
  
  names_x = as.character(an_x[,name_colsx[1]])
  names_y = as.character(an_y[,name_colsy[1]])
  shared = intersect(names_x,names_y)
  shared = setdiff(shared,c(NA,""))
  
  mx = x$sample_data
  my = y$sample_data
  
  if(any(table(names_x)>1)){
    mx = apply(mx,2,function(x,y)tapply(x,INDEX=y,FUN=mean,na.rm=T),y=names_x)
  }
  else{
    rownames(mx) = as.character(names_x)
  }
  if(any(table(names_y)>1)){
    my = apply(my,2,function(x,y)tapply(x,INDEX=y,FUN=mean,na.rm=T),y=names_y)
  }
  else{
    rownames(my) = as.character(names_y)
  }
  
  bid_x = as.character(merged_dmaqc_data[colnames(mx),"bid"])
  bid_y = as.character(merged_dmaqc_data[colnames(my),"bid"])
  if(sum(!is.element(bid_y,set=bid_x))>0){
    stop("BIDs do not match between x and y")
  } # should be zero
  colnames(mx) = bid_x
  colnames(my) = bid_y
  if(length(shared)>samplesize){
    shared = sample(shared)[1:samplesize]
  }
  mx = mx[shared,bid_y]
  my = my[shared,]
  mx = as.matrix(mx);my = as.matrix(my)
  if(nrow(mx)<2){return(NA)}
  if(length(shared)<=100){
    corrs = diag(cor(t(mx),t(my)))
  }
  else{
    corrs = c()
    for(i in 1:nrow(mx)){
      # print(mean(mx[i,]))
      corrs[rownames(mx)[i]] = cor(mx[i,],my[i,])
    }
  }
  return(mean(corrs))
}

```













